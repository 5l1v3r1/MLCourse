{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a column of ones to the first column of a dataframe\n",
    "# and turn it into a matrix\n",
    "def df_addOnes(dataFrame):\n",
    "    vals = dataFrame.values\n",
    "    add_ones_column = zip(np.ones(len(dataFrame)), vals)\n",
    "    return add_ones_column\n",
    "    feature_matrix = np.matrix([val for val in add_ones_column])\n",
    "    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making it easy to calculate the total penalty over the entire dataset\n",
    "def penalty(df_features, df_output, paramater_value_list):\n",
    "    \n",
    "    # df_features is a dataframe of the features (no column of ones added)\n",
    "    # df_output is a dataframe of the output column (target variable)\n",
    "    # parameter_value_list is a list of w0, w1, ..., wn+1 where n is the number of features\n",
    "    #  i.e., the number of columns in df_features.\n",
    "    \n",
    "    # Cost of being wrong calculated over the entire data set\n",
    "    # Will take X and add a first column of 1s to it to enable the matrix multiplication\n",
    "    # Therefore: X is an m x n matrix and theta is a n x 1 matrix\n",
    "    \n",
    "    #### Turn the function inputs into matrices ####\n",
    "    # Get X and y into the right shapes for use in computeCost\n",
    "    # Add a first column of ones to the feature matrix\n",
    "    # Add a column of 1s to X \n",
    "    feature_matrix = df_addOnes(df_features)\n",
    "\n",
    "    output_matrix = np.matrix(df_output.values)\n",
    "    parameter_matrix = np.matrix(paramater_value_list).T\n",
    "    \n",
    "    # Difference between the predicted and the actual value\n",
    "    error = (feature_matrix * parameter_matrix) - output_matrix\n",
    "    \n",
    "    # penaltyPerOutput is an m x 1 matrix where each element is the penalty for\n",
    "    # the input and its associated output for a particular value of W\n",
    "    \n",
    "    # Use the squared error penalty function\n",
    "    penaltyPerOutput = np.power(error, 2)\n",
    "    \n",
    "    # totalPenalty is the sum of the penalties of each row of the dataset\n",
    "    totalPenalty = np.sum(penaltyPerOutput)\n",
    "    \n",
    "    # The penalty of getting it wrong is 1/2m of the totalPenalty (normalized penalty)\n",
    "    # m is the number of rows in df_features\n",
    "    totalPenaltyNorm = totalPenalty / (2 * len(df_features))\n",
    "    \n",
    "    return totalPenaltyNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Gradient Descent\n",
    "def gradientDescent(X, y, W, alpha, iters):\n",
    "    # NOTE: X is the original dataframe -- need to add a column of ones to it and make it a matrix\n",
    "    feature_matrix = df_addOnes(X)\n",
    "    # feature_matrix is a m x n matrix\n",
    "    # y is a m x 1 matrix\n",
    "    # W is a n x 1 matrix\n",
    "    \n",
    "    # Keep track of everything\n",
    "    sumError = np.zeros(shape=(len(W),1))\n",
    "    sumErrorNorm = np.zeros(shape=(len(W),1))\n",
    "    temp = np.matrix(np.zeros(W.shape))\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # Calculate the non-normalized values for each W parameter\n",
    "        error = (feature_matrix * W) - y\n",
    "        # return feature_matrix.shape, W.shape, y.shape, error, feature_matrix[:,1]\n",
    "        \n",
    "        for j in range(len(W)):\n",
    "            # Multiply the error vector by the appropriate column of the feature_matrix and sum it\n",
    "            sumError[j] = np.sum(np.multiply(error, feature_matrix[:,j]))\n",
    "            \n",
    "            # Normalize the sumError using alpha and m\n",
    "            sumErrorNorm[j] = np.divide(np.multiply(sumError[j], alpha), len(feature_matrix))\n",
    "            \n",
    "            temp[j,0] = W[j,0] - sumErrorNorm[j]\n",
    "        \n",
    "        W = temp\n",
    "    \n",
    "        # Use the original dataframe in this call\n",
    "        # the penalty function likes to see W.T as input\n",
    "        cost[i] = penalty(X,y,W.T)\n",
    "            \n",
    "    # Return the value of W after iters iterations of gradient descent\n",
    "    # Return the penalty = cost for this W\n",
    "    return W, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Penalty Functions for a Single Feature\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
